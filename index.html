<!doctype html>
<html>


<head>
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>(py)ABC</title>

    <meta name="description"
          content="Likelihood-free Bayesian Inference and pyABC">
    <meta name="author" content="Yannik Schaelte">

    <link rel="stylesheet" href="reveal.js/dist/reset.css">
    <link rel="stylesheet" href="reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css" id="theme">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css"
          id="highlight-theme">

    <link rel="stylesheet" href="ystyle.css">
</head>


<body>
<div class="reveal">
    <div class="slides" id="id_slides">

        <section>
            <img src="img/front.svg" alt="Front page"/>
        </section>

        <section>
            <h1>Overview</h1>
            <ul>
                <li>Motivation for likelihood-free inference</li>
                <li>Basics of ABC</li>
                <li>pyABC: Features and usage</li>
            </ul>
        </section>

        <section data-background="#e4003a" data-background-transition="zoom">
            <h1>Why?</h1>
        </section>


        <section>
            <h2>Parameter inference</h2>
            <div class="r-stack">
                <img src="img/parameter_estimation_1.svg"/>
                <img class="fragment" src="img/parameter_estimation_2.svg"/>
                <img class="fragment" src="img/parameter_estimation_3.svg"/>
                <img class="fragment" src="img/parameter_estimation_4.svg"/>
            </div>
        </section>


        <section>
            <h2>(Likelihood-free) Bayesian inference</h2>
            <div class="r-stack">
                <img class="fragment" src="img/bayestheorem.svg"/>
                <img class="fragment" src="img/bayestheorem_lf.svg"/>
            </div>
            <ul>
                <li>
                    goal: infer parameters $\theta$ given
                    data $y_\text{obs}$,
                    i.e. analyze the posterior distribution</li>
                <li class="fragment">
                    common optimization and sampling methods require
                    the (unnormalized) likelihood</li>
                <li class="fragment">
                    can happen: numerical
                    <strong>evaluation infeasible</strong></li>
                <li class="fragment">
                    ... but <strong>possible to simulate data</strong>
                    $y\sim\pi(y|\theta)$</li>
            </ul>
        </section>


        <section>
            <h2>Multi-scale models</h2>
            <img src="img/multiscale_models.svg" class="stretch"
                 alt="Multiscale models"/>
            <small>based on Hasenauer et al., J. Coup. Sys. and Mult. Dyn. 2015</small>
        </section>


        <section>
            <h2>Example: Modeling tumor growth</h2>
            <small>based on Jagiella et al., Cell Systems 2017</small>
            <img src="img/dividing_bg_transparent_small.gif" class="stretch"
                 alt="Tumor gif"/>
            <ul>
                <li>cells modeled as interacting stochastic agents, dynamics of
                    extracellular substances by PDEs
                </li>
                <li>simulate up to 10<sup>6</sup> cells</li>
                <li>10s - 1h for one forward simulation</li>
                <li>7-18 parameters</li>
            </ul>
        </section>


        <section data-transition="slide-in fade-out">
            <table>
                <tr>
                    <td><h2>What we tried</h2></td>
                </tr>
                <tr>
                    <td>
                        <ul>
                            <li>multi-start local methods
                                <ul>
                                    <li>deterministic gradient descent</li>
                                    <ul>
                                        <li>Levenberg-Marquardt</li>
                                        <li>interior-point</li>
                                        <li>trust-region</li>
                                    </ul>
                                    <li>stochastic gradient descent</li>
                                    <li>Bayesian optimization</li>
                                </ul>
                            </li>
                            <li>global methods
                                <ul>
                                    <li>simulated annealing</li>
                                    <li>&gt; 20 particle methods</li>
                                    <li>enhanced scatter search</li>
                                </ul>
                            </li>
                        </ul>
                    </td>
                </tr>
            </table>
        </section>


        <section data-transition="fade-in slide-out">
            <table>
                <tr>
                    <td><h2 style="color: #B71C1C">Failed</span></h2></td>
                    <td><h2 style="color: #1B5E20">Worked</h2></td>
                </tr>
                <tr>
                    <td style="vertical-align: top; color: #B71C1C;">
                        <ul>
                            <li>multi-start local methods
                                <ul>
                                    <li>deterministic gradient descent</li>
                                        <ul>
                                            <li>Levenberg-Marquardt</li>
                                            <li>interior-point</li>
                                            <li>trust-region</li>
                                        </ul>
                                    <li>stochastic gradient descent</li>
                                    <li>Bayesian optimization</li>
                                </ul>
                            </li>
                            <li>global methods
                                <ul>
                                    <li>simulated annealing</li>
                                    <li>&gt; 20 particle methods</li>
                                    <li>enhanced scatter search</li>
                                </ul>
                            </li>
                        </ul>
                    </td>
                    <td style="vertical-align: top; color: #1B5E20;">---</td>
                </tr>
            </table>
        </section>


        <section data-transition="zoom-in fade-out">
            <h2>How to infer parameters for complex stochastic models?</h2>
        </section>


        <section data-background="#e4003a" data-background-transition="zoom">
            <h1>ABC</h1>
            Approximate Bayesian Computation
        </section>


        <script>
            var node = document.getElementById("id_slides");
            node.innerHTML += "<section data-transition='slide-in fade-out'><h2>Rejection ABC</h2><img src='img/abc_principles-0.svg' alt='ABC principles'/></section>"
            var i;
            for (i = 1; i < 8; i++) {
                node.innerHTML += "<section data-transition='fade'><h2>Rejection ABC</h2><img src='img/abc_principles-" + i + ".svg' alt='ABC principles'/></section>"
            }
        </script>


        <section>
            <section>
                <h2>Rejection ABC</h2>
                <div style="text-align: left">
                    With distance $d$, threshold $\varepsilon>0$:
                    <div class="r-frame">
                        until $N$ acceptances:<br/>
                        <ol>
                            <li>sample $\theta\sim g(\theta)$</li>
                            <li>simulate data $y\sim\pi(y|\theta)$</li>
                            <li>if $d(s(y), s(y_\text{obs}))\leq\varepsilon$, accept $\theta$ with probability $\propto \frac{g(\theta)}{f(\theta)}$</li>
                        </ol>
                    </div>
                </div>
            </section>

            <section>
                <h2>A "derivation"</h2>
            </section>

            <section>
                <h2>Rejection sampling</h2>
                <div style="text-align: left">
                    Background: Want to sample from $f$, but can only sample from
                    $g \gg f$.
                    <div class="r-frame">
                        until $N$ acceptances:<br/>
                        <ol>
                            <li>sample $\theta\sim g(\theta)$</li>
                            <li>accept $\theta$ with probability $\propto \frac{g(\theta)}{f(\theta)}$</li>
                        </ol>
                    </div>
                    Accepted $\theta$ are independent samples from $f(\theta)$.<br/>
                    Let $f=\pi(\theta|y_\text{obs}), g=\pi(\theta) \Rightarrow \frac{\pi(\theta|y_\text{obs})}{\pi(\theta)} \propto \pi(y_\text{obs}|\theta)$
                    <ul>
                        <li>not available</li>
                        <li>idea: <strong>circumvent likelihood evaluation</strong>
                            by <strong>simulating data</strong> and matching them
                            to the observed data</li>
                    </ul>
                </div>
            </section>

            <section>
                <h2>Likelihood-free rejection sampling</h2>
                <div style="text-align: left">
                    <div class="r-frame">
                        until $N$ acceptances:<br/>
                        <ol>
                            <li>sample $\theta\sim g(\theta)$</li>
                            <li>simulate data $y\sim\pi(y|\theta)$</li>
                            <li>if $y=y_\text{obs}$, accept $\theta$ with probability $\propto \frac{g(\theta)}{f(\theta)}$</li>
                        </ol>
                    </div>
                    <ul>
                        <li>Acceptance probability: $\mathbb{P}[y_\text{obs}]$</li>
                        <li>can be small in particular for continuous data</li>
                        <li>idea: accept simulations that are <strong>similar</strong> to $y_\text{obs}$</li>
                    </ul>
                </div>
            </section>

            <section>
                <h2>Rejection ABC</h2>
                <div style="text-align: left">
                    With distance $d$, threshold $\varepsilon>0$:
                    <div class="r-frame">
                        until $N$ acceptances:<br/>
                        <ol>
                            <li>sample $\theta\sim g(\theta)$</li>
                            <li>simulate data $y\sim\pi(y|\theta)$</li>
                            <li>if $d(y, y_\text{obs})\leq\varepsilon$, accept $\theta$ with probability $\propto \frac{g(\theta)}{f(\theta)}$</li>
                        </ol>
                    </div>
                    <ul>
                        <li><strong>curse of dimensionality:</strong>
                            if the data are too high-dimensional, the probability
                            of simualting similar data sets is small</li>
                        <li>idea: create an informative lower-dimensional
                            representation via <strong>summary statistics
                            </strong></li>
                        <li>ideally minimal sufficient statistics</li>
                    </ul>
                </div>
            </section>
        </section>


        <section>
            <h2>Toy example</h2>
            <div style="text-align: left">
                $y\sim\mathcal{N}(2(\theta-2)\theta(\theta+2), 1+\theta^2)$, $y_\text{obs}=2$<br/>
                $\pi(\theta) = U[-3,3]$<br/>
                $d=|{\cdot}|_1$<br/>
                $N=1000$ acceptances
                <div class="r-stack">
                    <img src="img/wino_1.png"/>
                    <img class="fragment" src="img/wino_2.png"/>
                    <img class="fragment" src="img/wino_3.png"/>
                    <img class="fragment" src="img/wino_4.png"/>
                    <img class="fragment" src="img/wino_5.png"/>
                </div>
            </div>
        </section>


        <section>
            <h2>Approximate Bayesian Posterior</h2>
            <p>
                We want:
                \[\pi(\theta|y_\text{obs}) \propto \color{red}{p(y_\text{obs}|\theta)}\pi(\theta)\]
            </p>
            <p class="fragment">
                We get:
                \[\pi_{ABC}(\theta|s(y_\text{obs})) \propto \color{red}{\int I(\{d(s(y), s(y_\text{obs})) \leq
                \varepsilon\})p(y|\theta)\operatorname{dy}}\pi(\theta) \approx
                \frac{1}{N} \sum_{i=1}^N\delta_{\theta^{(i)}}(\theta)\]
                with distance $d$, threshold $\varepsilon>0$, and summary
                statistics $s$
            </p>
        </section>


        <section>
            <h2>Sources of approximation errors in ABC</h2>
            <ul>
                <li>model error (as for every model of reality)</li>
                <li>Monte-Carlo error (as for sampling in general)</li>
                <li>summary statistics</li>
                <li>epsilon threshold</li>
            </ul>
            <div class="fragment">
                <blockquote>
                    Far better an approximate answer to the right question, which
                    is often vague, than an exact answer to the wrong question,
                    which can always be made precise.
                </blockquote>
                <div style="text-align: right"><small>John Tukey 1962</small></div>
            </div>
        </section>


        <section>
            <h2>Efficient samplers</h2>
            <ul>
                <li>Rejection ABC, the basic ABC algorithm, can be
                    <strong>inefficient</strong> repeatedly sampling from the
                    prior</li>
                <li>smaller $\varepsilon$ leads to lower acceptance rates</li>
                <li>many (likelihood-based) algorithms like IS, MCMC, SMC, SA
                    have <strong>ABC-fied</strong> versions</li>
            </ul>
        </section>


        <script>
            var node = document.getElementById("id_slides");
            node.innerHTML += "<section data-transition='slide-in fade-out'><h2>ABC-SMC</h2>combine with a sequential Monte-Carlo scheme<img src='img/abc_principles-8.svg' alt='ABC-SMC principles'/><small>similar to Toni et al., J. Royal Society 2009</small></section>"
            node.innerHTML += "<section data-transition='fade-in slide-out'><h2>ABC-SMC</h2>combine with a sequential Monte-Carlo scheme<img src='img/abc_principles-9.svg' alt='ABC-SMC principles'/><small>similar to Toni et al., J. Royal Society 2009</small></section>"
        </script>


        <section>
            <img src="img/abc_smc_better.svg"/>
        </section>


        <section data-background="#e4003a" data-background-transition="zoom">
            <img src="img/logo_white.svg" style="background: #ffffff00; border: none" alt="pyABC logo white"/><br/>
            <span style="font-family: monospace">github.com/icb-dcm/pyabc</span><br/>
            <small>Klinger et al., Bioinformatics 2018</small>
        </section>


        <section>
            <img src="img/logo.svg" alt="pyABC logo black"/>
            <img src="img/points_extended.svg" style="width: 90%;"
                 alt="Points"/>
        </section>


        <section>
            <h2>Easy to use</h2>
            <pre>
                <code class="python" data-trim>
# define problem
abc = pyabc.ABCSMC(model, prior, distance)

# pass data
abc.new(database, observation)

# run it
abc.run()
                </code>
            </pre>
        </section>


        <section>
            <h2>Parallel backends: 1 to 1,000s cores</h2>
            <img src="img/parallelization.svg" style="width: 40%"
                 alt="Parallelization backends"/>
        </section>


        <section>
            <h2>Parallelization strategies</h2>
            <small>Klinger et al., CMSB Proceedings 2017</small>
            <img src="img/strategies_illustration_small.svg"
                 alt="Parallelization strategies"/>
        </section>


        <section>
            <h1>Example: Tumor growth model</h1>
            <small>based on Jagiella et al., Cell Systems 2017</small>
        </section>


        <section>
            <h2>Define summary statistics</h2>
            <img src="img/tumor_sumstat.svg" class="stretch"
                 alt="Tumor summary statistics"/>
        </section>


        <section data-background="img/server_white.svg">
            <span style="font-weight: bold; font-size: 1.2em;">
            <ul>
                <li>400 cores</li>
                <li>3 days</li>
                <li>1.8e6 simulations</li>
            </ul>
            </span>
        </section>


        <section data-transition="slide-in fade-out">
            <img src="img/tumor_kdes_small.gif" class="stretch"
                 alt="Tumor KDEs"/>
            <div class="conclusion" style="background-color: #ffffff">
                ABC worked where many other methods had failed.
            </div>
        </section>


        <section data-transition="fade-in slide-out">
            <img src="img/dflt_37.png" class="stretch" alt="Tumor final KDE"/>
            <div class="conclusion">
                ABC worked where many other methods had failed.
            </div>
        </section>


        <section>
            <img class="r-stretch" src="img/tumor_integration.svg"/><br/>
            Uncertainty-aware predictions, easy data integration.
        </section>


        <section>
            <section>
                <h1>Some details</h1>
            </section>


            <section>
                <h2>Adaptive population sizes</h2>
                <small>Klinger et al., CMSB Proceedings 2017</small>
                <img src="img/adaptive_population_size_illustrations.svg"
                     alt="Adaptive population sizes"/>
                idea: adapt population size trying to match a target accuracy
            </section>


            <section>
                <h2>Self-tuning distance functions</h2>
                <small>based on Prangle, Bayesian Analysis 2015</small><br/>
                <img src="img/adaptive_distances.svg" class="stretch"
                     alt="Adaptive distances"/>
            </section>


            <section>
                <h2>Measurement noise</h2>
                How to efficiently account for measurement noise in ABC?
                <img src="img/concept.svg" class="stretch"
                     alt="Measurement noise methods"/>
            </section>


            <section>
                <h2>And ...</h2>
                <img src="img/and.svg" alt="And"/>
                <h2>...</h2>
            </section>
        </section>


        <section>
            <img src="img/logo_fmc_long.svg.png" height="70px"/><br/>
            Joint initiative to make ABC fit for multi-cellular
            models
            <img src="img/morpheus_gui.png" class="stretch" alt="Morpheus"/>
            <br/>
            <small>Morpheus toolbox: Staruß et al., Bioinformatics 2014</small>
        </section>


        <section data-background="#e4003a" data-background-transition="zoom"
                 data-auto-animate>
            <h1>Summary</h1>
        </section>


        <section data-auto-animate>
            <h1>Summary</h1>
            <div style="display: flex">
                <ul>
                    <li>parameter estimation when we cannot evaluate the
                        likelihood is challenging</li>
                    <li>ABC allows for reliable statistical inference</li>
                    <li>pyABC provides an easy-to-use framework</li>
                </ul>
                <span style="padding: 10px;">
                    <img src="img/rose_hammer.svg"/>
                    <small>Not everything is a nail.</small>
                </span>
            </div>
        </section>


        <section>
            <h2>Literature</h2>
            <img src="img/icon_book_inkscape.svg" height="70px"/>
            <ul>
                <li>Sisson, Scott A., Yanan Fan, and Mark Beaumont, eds.
                    Handbook of approximate Bayesian computation.
                    CRC Press, 2018.</li>
                <li>Beaumont, Mark A. "Approximate Bayesian computation in
                    evolution and ecology." Annual review of ecology,
                    evolution, and systematics 41 (2010): 379-406.</li>
                <li>Martin, Gael M., David T. Frazier, and Christian P.
                    Robert. "Computing Bayes: Bayesian Computation from
                    1763 to the 21st Century." arXiv preprint
                    arXiv:2004.06425 (2020).</li>
            </ul>
        </section>


        <section data-background="img/group.jpg">
            <div style="background-color: #ffffff99; text-align: left; padding: 30px;">
                <h3>Acknowledgments</h3>
                Thanks to: Jan Hasenauer (and the whole lab), Elba
                Raimúndez-Álvarez, Emad
                Alamoudi, the FitMultiCell team, ...
                <img src="img/ack.png"/>
            </div>
        </section>


        <section data-background-image="img/questions.jpg"
                 data-background-opacity="0.3">
            <h1>Thanks! Questions?</h1>
        </section>

    </div>
</div>


<script src="reveal.js/dist/reveal.js"></script>
<script src="reveal.js/plugin/zoom/zoom.js"></script>
<script src="reveal.js/plugin/notes/notes.js"></script>
<script src="reveal.js/plugin/markdown/markdown.js"></script>
<script src="reveal.js/plugin/highlight/highlight.js"></script>
<script src="reveal.js/plugin/math/math.js"></script>
<script>
// More info about initialization & config:
// - https://revealjs.com/initialization/
// - https://revealjs.com/config/
Reveal.initialize({
    controls: true,
    progress: true,
    center: true,
    hash: true,

    // Learn about plugins: https://revealjs.com/plugins/
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes,
               RevealMath, RevealZoom ]
});
//Reveal.configure({ slideNumber: 'c/t' });
//Reveal.configure({ showSlideNumber: 'all' });




</script>
</body>
</html>
